{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9a3cf8d6",
      "metadata": {
        "id": "9a3cf8d6"
      },
      "source": [
        "### Use logistic regression for MNIST\n",
        "\n",
        "Logistic regression can be implemented by a FC layer, with the cross entropy loss. To use it for MNIST, we can \"flatten\" the input data into a 1D array, and use a trainable FC layer\n",
        "\n",
        "**important**: before turning in your final notebook for grading, make sure to make a \"clean\" run. Choose \"Restart & Run All\" from the \"Kernel\" pulldown menu. The indices of runs **must** be sequential and start with 1\n",
        "\n",
        "**important**: rename the notebook with your UID as the prefix, such as jdoe001_xxxxxxx.ipynb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "96b8e75e",
      "metadata": {
        "id": "96b8e75e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils as utils\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the transform to normalize the data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ],
      "metadata": {
        "id": "F12sS4NFQWr6"
      },
      "id": "F12sS4NFQWr6",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "54703df4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54703df4",
        "outputId": "a5505e8d-2fa6-451d-bc28-80e302070a42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 60000\n",
            "Number of testing samples: 10000\n"
          ]
        }
      ],
      "source": [
        "## To be implemented\n",
        "## load MNIST and print stats\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Print the stats\n",
        "print(f\"Number of training samples: {len(trainset)}\")\n",
        "print(f\"Number of testing samples: {len(testset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4b4c7121",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "4b4c7121",
        "outputId": "050889a1-8d76-4436-ba94-0684138118d2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "## To be implemented\n",
        "## visualize as 2x2 panel, randomly choose 2 from training and 2 from test sets\n",
        "def visualize_selected_images(dataset, selected_labels):\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    for i, label in enumerate(selected_labels, 1):\n",
        "        # Filter images by label\n",
        "        filtered_indices = [idx for idx, (_, target) in enumerate(dataset) if target == label]\n",
        "        # Randomly select an image\n",
        "        selected_index = random.choice(filtered_indices)\n",
        "        image, label = dataset[selected_index]\n",
        "        plt.subplot(2, 2, i)\n",
        "        plt.imshow(image.squeeze(), cmap='gray')\n",
        "        plt.title(f\"Label: {label}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "# Selected labels to visualize\n",
        "selected_labels = [4, 5]\n",
        "\n",
        "# Visualize selected labels from training set\n",
        "visualize_selected_images(trainset, selected_labels)\n",
        "\n",
        "# Visualize selected labels from test set\n",
        "visualize_selected_images(testset, selected_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56911745",
      "metadata": {
        "id": "56911745"
      },
      "source": [
        "**Important**: make sure to use your best hyper-parameters, I have achieved the test accuracy of >88% by tuning them, using CPU only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4e564bbf",
      "metadata": {
        "id": "4e564bbf"
      },
      "outputs": [],
      "source": [
        "## put your best hyperparameters\n",
        "## hyperparameters\n",
        "input_size = 28*28  #Size of image\n",
        "num_classes = 10  #the image number are in range 0-10\n",
        "num_epochs = 5 #one cycle through the full train data\n",
        "batch_size = 100 #sample size consider before updating the model’s weights\n",
        "learning_rate = 0.01  #step size to update parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2c032988",
      "metadata": {
        "id": "2c032988"
      },
      "outputs": [],
      "source": [
        "## To be implemented\n",
        "## create dataloaders\n",
        "train_loader = utils.data.DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = utils.data.DataLoader(dataset=testset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "331a03c6",
      "metadata": {
        "id": "331a03c6"
      },
      "outputs": [],
      "source": [
        "## To be implemented\n",
        "## build the model\n",
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self, input_size, num_classes):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    # Define the fully connected layer\n",
        "    self.linear = nn.Linear(input_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Flatten the image tensors\n",
        "    x = x.view(-1, input_size)\n",
        "    # Forward pass through the linear layer\n",
        "    out = self.linear(x)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "341a19ae",
      "metadata": {
        "id": "341a19ae"
      },
      "outputs": [],
      "source": [
        "## set up loss and optimizer\n",
        "model = LogisticRegression(input_size,num_classes)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "## you are free to use other optimizers\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a15a6b47",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a15a6b47",
        "outputId": "6165e630-8d2c-400e-f006-531f6c6852e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iternation: 200, training loss = 0.613\n",
            "Iternation: 400, training loss = 0.544\n",
            "Iternation: 600, training loss = 0.492\n",
            "==> Epoch: 0, test accuracy = 88.660\n",
            "Iternation: 200, training loss = 0.372\n",
            "Iternation: 400, training loss = 0.381\n",
            "Iternation: 600, training loss = 0.311\n",
            "==> Epoch: 1, test accuracy = 89.940\n",
            "Iternation: 200, training loss = 0.436\n",
            "Iternation: 400, training loss = 0.428\n",
            "Iternation: 600, training loss = 0.286\n",
            "==> Epoch: 2, test accuracy = 90.450\n",
            "Iternation: 200, training loss = 0.308\n",
            "Iternation: 400, training loss = 0.252\n",
            "Iternation: 600, training loss = 0.356\n",
            "==> Epoch: 3, test accuracy = 90.730\n",
            "Iternation: 200, training loss = 0.237\n",
            "Iternation: 400, training loss = 0.268\n",
            "Iternation: 600, training loss = 0.438\n",
            "==> Epoch: 4, test accuracy = 90.950\n",
            "Final Accuracy = 90.95%\n"
          ]
        }
      ],
      "source": [
        "## To be implemented\n",
        "## training test testing\n",
        "for epoch in range(num_epochs):\n",
        "    ## your code here\n",
        "    model.train()  # Set the model to training mode\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Flatten MNIST images to a 784 vector for each image\n",
        "        images = images.view(-1, 28*28)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        compute_loss = loss(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        compute_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        ## printing training losses\n",
        "        if (i+1) % 200 == 0:\n",
        "            print('Iternation: {0}, training loss = {1:.3f}'.format(i+1,compute_loss.item()))\n",
        "\n",
        "\n",
        "    ## Run testing after each epoch\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        total = 0\n",
        "        accurate = 0\n",
        "\n",
        "        ## your code here\n",
        "        for images, labels in test_loader:\n",
        "            images = images.view(-1, 28*28)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            accurate += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "        accuracy_score = 100*accurate/total\n",
        "        print('==> Epoch: {0}, test accuracy = {1:.3f}'.format(epoch, accuracy_score))\n",
        "\n",
        "print('Final Accuracy = {0:.2f}%'.format(accuracy_score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3142a565",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3142a565",
        "outputId": "25eed170-dfc5-4328-e6e0-9eb28c94ab59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(\n",
            "  (linear): Linear(in_features=784, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "## model stats\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "856ccda6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "856ccda6",
        "outputId": "7e358b89-20fc-4eca-aa47-1eb7dbab2b98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                   [-1, 10]           7,850\n",
            "================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.03\n",
            "Estimated Total Size (MB): 0.03\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "## optional, print model statistics\n",
        "from torchsummary import summary\n",
        "summary(model, input_size=(1, 28*28))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}